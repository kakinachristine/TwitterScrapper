{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                        date                   id  \\\n0  2023-04-12 08:05:43+00:00  1646062024852668418   \n1  2023-04-12 08:05:34+00:00  1646061984264355841   \n2  2023-04-12 08:04:49+00:00  1646061799136174082   \n3  2023-04-12 08:04:28+00:00  1646061709746896897   \n4  2023-04-12 08:04:04+00:00  1646061607829618688   \n5  2023-04-12 08:04:02+00:00  1646061599852048385   \n6  2023-04-12 08:03:58+00:00  1646061584991567873   \n7  2023-04-12 08:03:04+00:00  1646061355621928960   \n8  2023-04-12 08:02:57+00:00  1646061327285116929   \n9  2023-04-12 08:02:54+00:00  1646061316057219073   \n\n                                             content        username  \\\n0  é¢¨ã®å¼·ã„æ—¥ã§ã—ãŸ\\n#ã‚»ãƒ«ãƒ•ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆ #nana_camera \\n#ä¸­æ€§ä¿³å„ª #ãƒ¢ãƒ‡ãƒ«...   irodor1midori   \n1  #Pokekara å‹ã®å¤šé‡ãƒãƒ¢ãƒªã‚³ãƒ¼ãƒ©ã‚¹ã§ç››ã‚Šä¸Šã’ã¦ãã‚Œã¦ã„ã¾ã™ã€‚ #ä¸­å±±ç¾ç©‚ã€ã€€#è‰²ãƒ›ãƒ¯...         haoyu52   \n2  é‹å‹•ã™ã‚‹ã¨é ­ã‚’ç©ºã«å‡ºæ¥ã‚‹ã‹ã‚‰æ°—ã«ãªã£ã¦ãŸã“ã¨ã‚’æ•´ç†ã™ã‚‹ãã£ã‹ã‘ã«ã‚‚ãªã‚‹ğŸ‘ğŸ‘\\nçµ‚ã‚ã£ãŸå¾Œã®é”...     ken19891016   \n3  #gay #LaMasDraga #boy #gaykiss #kep1er #LESSER...       aaasael27   \n4  Sen ancak @RTErdogan'Ä±n tÄ±rnaÄŸÄ±ndan Ã¶zÃ¼r diler...  marjinal_koylu   \n5  Hora de descansar estas nalgas jajaja #gay htt...       pepecol69   \n6        Pussy! \\n\\n#LGBTQIA https://t.co/Dr0QpVKr0T    JustChillieh   \n7  La Procura di #Padova ha chiesto al Comune gli...   BiribissiBlog   \n8  Research is key to every #Crypto investmentğŸ—£ï¸ ...        RBIF_USA   \n9  é«ªä¼¸ã³ã¾ã—ãŸã€‚\\nL/20ä»£/æ±åŒ—\\nå¥½ããªã‚‚ã®ã¯ã€ããªã“é¤…ã›ã‚“ã¹ã„\\nå«Œã„ãªã‚‚ã®ã¯ä¿¡å·ã¨æ¨ª...       izumi_Si3   \n\n   likeCount  retweetCount               location  \\\n0          0             0                    NaN   \n1          0             0                  æ—¥æœ¬ æ±äº¬   \n2          0             0                    NaN   \n3          0             0         Ahome, Sinaloa   \n4          0             0                    NaN   \n5          0             0         Colima, MÃ©xico   \n6          1             0  Palm Beach County, FL   \n7          0             0       Sanremo, Liguria   \n8          2             0            Buffalo, NY   \n9          0             0                    NaN   \n\n                                             hashtag  \\\n0  ['ã‚»ãƒ«ãƒ•ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆ', 'nana_camera', 'ä¸­æ€§ä¿³å„ª', 'ãƒ¢ãƒ‡ãƒ«', 'L...   \n1  ['Pokekara', 'ä¸­å±±ç¾ç©‚', 'è‰²ãƒ›ãƒ¯ã‚¤ãƒˆãƒ–ãƒ¬ãƒ³ãƒ‰', 'Gçµ„åˆå“¡', 'Gay...   \n2  ['æ‚©ã¿ç›¸è«‡', 'æ‚©ã¿èã„ã¦', 'ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼', 'ã‚±ã‚¢ãƒãƒ', 'LGBTQ', '...   \n3  ['gay', 'LaMasDraga', 'boy', 'gaykiss', 'kep1e...   \n4                   ['LGBT', 'ErdoÄŸanYineKazanacak']   \n5                                            ['gay']   \n6                                        ['LGBTQIA']   \n7                          ['Padova', 'gay', 'ANSA']   \n8  ['Crypto', 'DYOR', 'Finance', 'RoboInu', 'Bank...   \n9  ['LGBTQ', 'LGBTã•ã‚“ã¨ç¹‹ãŒã‚ŠãŸã„', 'ã‚»ã‚¯ãƒã‚¤', 'ã‚»ã‚¯ãƒã‚¤ã•ã‚“ã¨ç¹‹ãŒã‚ŠãŸ...   \n\n                                              source  \n0  <a href=\"http://twitter.com/download/android\" ...  \n1  <a href=\"http://www.pokekara.com\" rel=\"nofollo...  \n2  <a href=\"http://twitter.com/download/iphone\" r...  \n3  <a href=\"http://twitter.com/download/iphone\" r...  \n4  <a href=\"http://twitter.com/download/android\" ...  \n5  <a href=\"http://twitter.com/download/android\" ...  \n6  <a href=\"http://twitter.com/download/iphone\" r...  \n7  <a href=\"http://twitter.com/download/android\" ...  \n8  <a href=\"http://twitter.com/download/iphone\" r...  \n9  <a href=\"http://twitter.com/download/android\" ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>id</th>\n      <th>content</th>\n      <th>username</th>\n      <th>likeCount</th>\n      <th>retweetCount</th>\n      <th>location</th>\n      <th>hashtag</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-04-12 08:05:43+00:00</td>\n      <td>1646062024852668418</td>\n      <td>é¢¨ã®å¼·ã„æ—¥ã§ã—ãŸ\\n#ã‚»ãƒ«ãƒ•ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆ #nana_camera \\n#ä¸­æ€§ä¿³å„ª #ãƒ¢ãƒ‡ãƒ«...</td>\n      <td>irodor1midori</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>['ã‚»ãƒ«ãƒ•ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆ', 'nana_camera', 'ä¸­æ€§ä¿³å„ª', 'ãƒ¢ãƒ‡ãƒ«', 'L...</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-04-12 08:05:34+00:00</td>\n      <td>1646061984264355841</td>\n      <td>#Pokekara å‹ã®å¤šé‡ãƒãƒ¢ãƒªã‚³ãƒ¼ãƒ©ã‚¹ã§ç››ã‚Šä¸Šã’ã¦ãã‚Œã¦ã„ã¾ã™ã€‚ #ä¸­å±±ç¾ç©‚ã€ã€€#è‰²ãƒ›ãƒ¯...</td>\n      <td>haoyu52</td>\n      <td>0</td>\n      <td>0</td>\n      <td>æ—¥æœ¬ æ±äº¬</td>\n      <td>['Pokekara', 'ä¸­å±±ç¾ç©‚', 'è‰²ãƒ›ãƒ¯ã‚¤ãƒˆãƒ–ãƒ¬ãƒ³ãƒ‰', 'Gçµ„åˆå“¡', 'Gay...</td>\n      <td>&lt;a href=\"http://www.pokekara.com\" rel=\"nofollo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-04-12 08:04:49+00:00</td>\n      <td>1646061799136174082</td>\n      <td>é‹å‹•ã™ã‚‹ã¨é ­ã‚’ç©ºã«å‡ºæ¥ã‚‹ã‹ã‚‰æ°—ã«ãªã£ã¦ãŸã“ã¨ã‚’æ•´ç†ã™ã‚‹ãã£ã‹ã‘ã«ã‚‚ãªã‚‹ğŸ‘ğŸ‘\\nçµ‚ã‚ã£ãŸå¾Œã®é”...</td>\n      <td>ken19891016</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>['æ‚©ã¿ç›¸è«‡', 'æ‚©ã¿èã„ã¦', 'ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼', 'ã‚±ã‚¢ãƒãƒ', 'LGBTQ', '...</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-04-12 08:04:28+00:00</td>\n      <td>1646061709746896897</td>\n      <td>#gay #LaMasDraga #boy #gaykiss #kep1er #LESSER...</td>\n      <td>aaasael27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Ahome, Sinaloa</td>\n      <td>['gay', 'LaMasDraga', 'boy', 'gaykiss', 'kep1e...</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-04-12 08:04:04+00:00</td>\n      <td>1646061607829618688</td>\n      <td>Sen ancak @RTErdogan'Ä±n tÄ±rnaÄŸÄ±ndan Ã¶zÃ¼r diler...</td>\n      <td>marjinal_koylu</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>['LGBT', 'ErdoÄŸanYineKazanacak']</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2023-04-12 08:04:02+00:00</td>\n      <td>1646061599852048385</td>\n      <td>Hora de descansar estas nalgas jajaja #gay htt...</td>\n      <td>pepecol69</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Colima, MÃ©xico</td>\n      <td>['gay']</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2023-04-12 08:03:58+00:00</td>\n      <td>1646061584991567873</td>\n      <td>Pussy! \\n\\n#LGBTQIA https://t.co/Dr0QpVKr0T</td>\n      <td>JustChillieh</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Palm Beach County, FL</td>\n      <td>['LGBTQIA']</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2023-04-12 08:03:04+00:00</td>\n      <td>1646061355621928960</td>\n      <td>La Procura di #Padova ha chiesto al Comune gli...</td>\n      <td>BiribissiBlog</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Sanremo, Liguria</td>\n      <td>['Padova', 'gay', 'ANSA']</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2023-04-12 08:02:57+00:00</td>\n      <td>1646061327285116929</td>\n      <td>Research is key to every #Crypto investmentğŸ—£ï¸ ...</td>\n      <td>RBIF_USA</td>\n      <td>2</td>\n      <td>0</td>\n      <td>Buffalo, NY</td>\n      <td>['Crypto', 'DYOR', 'Finance', 'RoboInu', 'Bank...</td>\n      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2023-04-12 08:02:54+00:00</td>\n      <td>1646061316057219073</td>\n      <td>é«ªä¼¸ã³ã¾ã—ãŸã€‚\\nL/20ä»£/æ±åŒ—\\nå¥½ããªã‚‚ã®ã¯ã€ããªã“é¤…ã›ã‚“ã¹ã„\\nå«Œã„ãªã‚‚ã®ã¯ä¿¡å·ã¨æ¨ª...</td>\n      <td>izumi_Si3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>['LGBTQ', 'LGBTã•ã‚“ã¨ç¹‹ãŒã‚ŠãŸã„', 'ã‚»ã‚¯ãƒã‚¤', 'ã‚»ã‚¯ãƒã‚¤ã•ã‚“ã¨ç¹‹ãŒã‚ŠãŸ...</td>\n      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read in the data\n",
    "tweets_df = pd.read_csv(r\"C:\\Users\\user\\PycharmProjects\\TwitterYouths\\lgbtq_hashtags.csv\")\n",
    "tweets_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "tweets_df.drop_duplicates(subset=\"content\",keep=\"first\",inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Remove symbols, numbers, and URL links\n",
    "tweets_df['content'] = tweets_df['content'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "tweets_df['content'] = tweets_df['content'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "tweets_df['content'] = tweets_df['content'].apply(lambda x: re.sub(r'https?://\\S+', '', x))\n",
    "tweets_df['content'] = tweets_df['content'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "tweets_df['content'] = tweets_df['content'].apply(lambda x: re.sub(r'#\\S+', '', x))\n",
    "tweets_df[\"content\"]= tweets_df['content'].replace(r'\\r', ' ', regex=True)\n",
    "tweets_df[\"content\"]= tweets_df['content'].replace(r'\\n', ' ', regex=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0        é¢¨ã®å¼·ã„æ—¥ã§ã—ãŸ ã‚»ãƒ«ãƒ•ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆ nana_camera  ä¸­æ€§ä¿³å„ª ãƒ¢ãƒ‡ãƒ« LGBTQ...\n1        Pokekara å‹ã®å¤šé‡ãƒãƒ¢ãƒªã‚³ãƒ¼ãƒ©ã‚¹ã§ç››ã‚Šä¸Šã’ã¦ãã‚Œã¦ã„ã¾ã™ ä¸­å±±ç¾ç©‚ã€€è‰²ãƒ›ãƒ¯ã‚¤ãƒˆãƒ–ãƒ¬ãƒ³...\n2        é‹å‹•ã™ã‚‹ã¨é ­ã‚’ç©ºã«å‡ºæ¥ã‚‹ã‹ã‚‰æ°—ã«ãªã£ã¦ãŸã“ã¨ã‚’æ•´ç†ã™ã‚‹ãã£ã‹ã‘ã«ã‚‚ãªã‚‹ çµ‚ã‚ã£ãŸå¾Œã®é”æˆæ„Ÿãª...\n3        gay LaMasDraga boy gaykiss keper LESSERAFIM Ne...\n4        Sen ancak RTErdoganÄ±n tÄ±rnaÄŸÄ±ndan Ã¶zÃ¼r dilersi...\n                               ...                        \n14997    Guten Morgen ihr lieben  wÃ¼nsche euch schonmal...\n14998    Its all happening in  minutes You all know whe...\n14999    Not sure why everyone is so worried about Tran...\n15000    elio_vito Libero_official alesallusti Pan per ...\n15001    Open VcsBo pijat  gay gayindo GayIndonesia gay...\nName: content, Length: 14691, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Remove emojis\n",
    "def remove_emojis(content):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', content)\n",
    "\n",
    "tweets_df['content'] = tweets_df['content'].apply(remove_emojis)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords\u001B[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001B[0m, in \u001B[0;36mLazyCorpusLoader.__load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 84\u001B[0m     root \u001B[38;5;241m=\u001B[39m \u001B[43mnltk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubdir\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mzip_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py:583\u001B[0m, in \u001B[0;36mfind\u001B[1;34m(resource_name, paths)\u001B[0m\n\u001B[0;32m    582\u001B[0m resource_not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mmsg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 583\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(resource_not_found)\n",
      "\u001B[1;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords.zip/stopwords/\u001B[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [7], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Remove stop words and lemmatize\u001B[39;00m\n\u001B[0;32m      2\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpunkt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m stop_words \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[43mstopwords\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwords\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m      4\u001B[0m lemmatizer \u001B[38;5;241m=\u001B[39m WordNetLemmatizer()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_text\u001B[39m(text):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001B[0m, in \u001B[0;36mLazyCorpusLoader.__getattr__\u001B[1;34m(self, attr)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__bases__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    119\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLazyCorpusLoader object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__bases__\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__load\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# __class__ to something new:\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, attr)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001B[0m, in \u001B[0;36mLazyCorpusLoader.__load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     84\u001B[0m             root \u001B[38;5;241m=\u001B[39m nltk\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubdir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mzip_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m:\n\u001B[1;32m---> 86\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m     88\u001B[0m \u001B[38;5;66;03m# Load the corpus.\u001B[39;00m\n\u001B[0;32m     89\u001B[0m corpus \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__reader_cls(root, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__kwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001B[0m, in \u001B[0;36mLazyCorpusLoader.__load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 81\u001B[0m         root \u001B[38;5;241m=\u001B[39m \u001B[43mnltk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubdir\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     83\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\data.py:583\u001B[0m, in \u001B[0;36mfind\u001B[1;34m(resource_name, paths)\u001B[0m\n\u001B[0;32m    581\u001B[0m sep \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m70\u001B[39m\n\u001B[0;32m    582\u001B[0m resource_not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mmsg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 583\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(resource_not_found)\n",
      "\u001B[1;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords\u001B[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\user/nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words and lemmatize\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "tweets_df['content'] = tweets_df['content'].apply(process_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}